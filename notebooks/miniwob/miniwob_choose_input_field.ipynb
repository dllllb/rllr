{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "device = \"cuda:1\"\n",
    "\n",
    "chrome_driver_path = \"/mnt/akostin/home/akostin/prjs/utils/chromedriver/\"\n",
    "app_path = \"/mnt/akostin/home/akostin/prjs/utils/chromedriver/\"\n",
    "os.environ[\"PATH\"] += os.pathsep + app_path\n",
    "os.environ[\"MINIWOB_BASE_URL\"] = \"file:///mnt/akostin/home/akostin/prjs/miniwob-plusplus/html/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: file:///mnt/akostin/home/akostin/prjs/miniwob-plusplus/html/\n"
     ]
    }
   ],
   "source": [
    "from miniwob.environment import MiniWoBEnvironment\n",
    "from miniwob.screenshot import pil_to_numpy_array\n",
    "\n",
    "task_name = 'login-user'\n",
    "base_url = os.environ.get('MINIWOB_BASE_URL')\n",
    "print('BASE URL:', base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_MAX, Y_MAX = 160, 210\n",
    "DOM_TEXT_MAX_TOKENS = 8\n",
    "GOAL_MAX_TOKENS = 16\n",
    "DOM_MAX_EDGES = 20\n",
    "DOM_MAX_VERTICES = 20\n",
    "\n",
    "username_element_id = 1\n",
    "password_element_id = 4\n",
    "username_idx = 4\n",
    "passwd_idx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from miniwob.action import  MiniWoBElementClick, MiniWoBType\n",
    "import numpy as np\n",
    "\n",
    "env = MiniWoBEnvironment(task_name, seeds=[1], num_instances=1, base_url=base_url, headless=True)\n",
    "state = env.reset(record_screenshots=True, seeds=[113])[0]\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Enter',\n",
       " 'the',\n",
       " 'username',\n",
       " '\"',\n",
       " 'juan',\n",
       " '\"',\n",
       " 'and',\n",
       " 'the',\n",
       " 'password',\n",
       " '\"',\n",
       " 'mEU',\n",
       " '\"',\n",
       " 'into',\n",
       " 'the',\n",
       " 'text',\n",
       " 'fields',\n",
       " 'and',\n",
       " 'press',\n",
       " 'login',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juan\n",
      "mEU\n"
     ]
    }
   ],
   "source": [
    "print(state.tokens[username_idx])\n",
    "print(state.tokens[passwd_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "input_text\n",
      "p\n",
      "label\n",
      "input_password\n",
      "p\n",
      "button\n",
      "div\n",
      "div\n",
      "div\n",
      "body\n"
     ]
    }
   ],
   "source": [
    "tags = set()\n",
    "for elem in state.dom_elements:\n",
    "    tags.add(elem.tag)\n",
    "    print(elem.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body', 'button', 'div', 'input_password', 'input_text', 'label', 'p'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 0,\n",
       " 'button': 1,\n",
       " 'input_text': 2,\n",
       " 'input_password': 3,\n",
       " 'div': 4,\n",
       " 'p': 5,\n",
       " 'label': 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6] label @ (2, 62) text='Username' classes=[bold],\n",
       " [7] input_text @ (7, 78) value= classes=[NO_CLASS],\n",
       " [5] p @ (2, 62) classes=[NO_CLASS] children=2,\n",
       " [9] label @ (2, 114) text='Password' classes=[bold],\n",
       " [10] input_password @ (7, 130) value= classes=[NO_CLASS],\n",
       " [8] p @ (2, 114) classes=[NO_CLASS] children=2,\n",
       " [11] button @ (2, 166) text='Login' classes=[secondary-action],\n",
       " [4] div @ (2, 62) classes=[NO_CLASS] children=3,\n",
       " [3] div @ (0, 50) classes=[NO_CLASS] children=1,\n",
       " [2] div @ (0, 0) classes=[NO_CLASS] children=1,\n",
       " [1] body @ (0, 0) classes=[NO_CLASS] children=1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.dom_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6] label @ (2, 62) text='Username' classes=[bold],\n",
       " [7] input_text @ (7, 78) value= classes=[NO_CLASS],\n",
       " [5] p @ (2, 62) classes=[NO_CLASS] children=2,\n",
       " [9] label @ (2, 114) text='Password' classes=[bold],\n",
       " [10] input_password @ (7, 130) value= classes=[NO_CLASS],\n",
       " [8] p @ (2, 114) classes=[NO_CLASS] children=2,\n",
       " [11] button @ (2, 166) text='Login' classes=[secondary-action],\n",
       " [4] div @ (2, 62) classes=[NO_CLASS] children=3,\n",
       " [3] div @ (0, 50) classes=[NO_CLASS] children=1,\n",
       " [2] div @ (0, 0) classes=[NO_CLASS] children=1,\n",
       " [1] body @ (0, 0) classes=[NO_CLASS] children=1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.dom_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acfd2040>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/75437c6cee53e2092d3d9b0b8cad5d91\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17cc702520>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/75437c6cee53e2092d3d9b0b8cad5d91\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17cc6fde80>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/75437c6cee53e2092d3d9b0b8cad5d91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0.0 [6] label @ (2, 62) text='Username' classes=[bold]\n",
      "False 0.0 [7] input_text @ (7, 78) value= classes=[NO_CLASS]\n",
      "False 0.0 [10] input_password @ (7, 130) value= classes=[NO_CLASS]\n",
      "False 0.0 [3] div @ (0, 50) classes=[NO_CLASS] children=1\n",
      "False 0.0 [9] label @ (2, 114) text='Password' classes=[bold]\n",
      "False 0.0 [10] input_password @ (7, 130) value= classes=[NO_CLASS]\n",
      "False 0.0 [8] p @ (2, 114) classes=[NO_CLASS] children=2\n",
      "False 0.0 [9] label @ (2, 114) text='Password' classes=[bold]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf916a0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b26f7db5fa122c8eff35d1188c727e14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0.0 [9] label @ (2, 114) text='Password' classes=[bold]\n",
      "False 0.0 [6] label @ (2, 62) text='Username' classes=[bold]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf83070>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b26f7db5fa122c8eff35d1188c727e14\n"
     ]
    }
   ],
   "source": [
    "env = MiniWoBEnvironment(task_name, seeds=[1], num_instances=1, base_url=base_url, headless=True)\n",
    "state = env.reset(record_screenshots=True, seeds=[1123])[0]\n",
    "done = False\n",
    "\n",
    "for _ in range(10):\n",
    "    random_element = np.random.choice(state.dom_elements)\n",
    "    action = [MiniWoBElementClick(random_element)]\n",
    "    obs, reward, done, infos = env.step(action)\n",
    "    print(done[0], reward[0], random_element)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf83370>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b26f7db5fa122c8eff35d1188c727e14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0.0 [9] label @ (2, 114) text='Password' classes=[bold]\n",
      "False 0.0 [4] div @ (2, 62) classes=[NO_CLASS] children=3\n",
      "False 0.0 [7] input_text @ (7, 78) value= classes=[NO_CLASS]\n",
      "False 0.0 [8] p @ (2, 114) classes=[NO_CLASS] children=2\n",
      "False 0.0 [2] div @ (0, 0) classes=[NO_CLASS] children=1\n",
      "False 0.0 [10] input_password @ (7, 130) value= classes=[NO_CLASS]\n",
      "False 0.0 [11] button @ (2, 166) text='Login' classes=[secondary-action]\n",
      "False 0.0 [5] p @ (2, 62) classes=[NO_CLASS] children=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf79b20>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/4675add9652bb293f7ab934d5cce5c3f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0.0 [4] div @ (2, 62) classes=[NO_CLASS] children=3\n",
      "False 0.0 [9] label @ (2, 114) text='Password' classes=[bold]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17604e5b50>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/4675add9652bb293f7ab934d5cce5c3f\n"
     ]
    }
   ],
   "source": [
    "env = MiniWoBEnvironment(task_name, seeds=[1], num_instances=1, base_url=base_url, headless=True)\n",
    "state = env.reset(record_screenshots=True, seeds=[1123])[0]\n",
    "done = False\n",
    "\n",
    "for _ in range(10):\n",
    "    random_element = np.random.choice(state.dom_elements)\n",
    "    action = [MiniWoBType(\"qwe\")]\n",
    "    obs, reward, done, infos = env.step(action)\n",
    "    print(done[0], reward[0], random_element)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf25be0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/4675add9652bb293f7ab934d5cce5c3f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] input_text @ (7, 78) value= classes=[NO_CLASS]\n",
      "[10] input_password @ (7, 130) value= classes=[NO_CLASS]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf83790>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/f48c12d40a2a31bea374baede79eb477\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf79b80>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/f48c12d40a2a31bea374baede79eb477\n"
     ]
    }
   ],
   "source": [
    "env = MiniWoBEnvironment(task_name, seeds=[1], num_instances=1, base_url=base_url, headless=True)\n",
    "state = env.reset(record_screenshots=True, seeds=[111])[0]\n",
    "print(state.dom_elements[username_element_id])\n",
    "print(state.dom_elements[password_element_id])\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym miniwob wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f17acf839d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/f48c12d40a2a31bea374baede79eb477\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "\n",
    "from miniwob.action import MiniWoBElementClick, MiniWoBFocusAndType\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MiniWobClickElementWrapper(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        bert_model = 'bert-base-cased'\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        self.observation_space = gym.spaces.Dict({\"goal_state\": gym.spaces.Box(0, \n",
    "                                                                               self.tokenizer.vocab_size,\n",
    "                                                                               (GOAL_MAX_TOKENS, ),\n",
    "                                                                               dtype=np.int64),\n",
    "                                                  \"img_state\": gym.spaces.Box(0,\n",
    "                                                                              255,\n",
    "                                                                              (150, 150, 3),\n",
    "                                                                              dtype=np.uint8),\n",
    "                                                  \"dom_simple_feats\": gym.spaces.Box(-1,\n",
    "                                                                                     1,\n",
    "                                                                                     (DOM_MAX_VERTICES, 3),\n",
    "                                                                                     dtype=np.float32),\n",
    "                                                  \"dom_text_tokens\": gym.spaces.Box(0,\n",
    "                                                                                    self.tokenizer.vocab_size,\n",
    "                                                                                    (DOM_MAX_VERTICES, DOM_TEXT_MAX_TOKENS),\n",
    "                                                                                    dtype=np.int64),\n",
    "                                                  \"dom_tags\": gym.spaces.Box(0,\n",
    "                                                                             len(tags)-1,\n",
    "                                                                             (DOM_MAX_VERTICES,),\n",
    "                                                                             dtype=np.int64)})\n",
    "        \n",
    "        self.need_username = [True for _ in range(self.num_instances)]\n",
    "        self.need_password = [True for _ in range(self.num_instances)]\n",
    "        self.inst_verts = [None for _ in range(self.num_instances)]\n",
    "        self.usernames = [\"\" for _ in range(self.num_instances)]\n",
    "        self.passwords = [\"\" for _ in range(self.num_instances)]\n",
    "        self.dom_keys = [key for key in self.observation_space if key.startswith(\"dom\")]\n",
    "        self.action_space = gym.spaces.Discrete(DOM_MAX_VERTICES)\n",
    "    \n",
    "    def _ob_to_dom(self, ob, i):\n",
    "        max_length = DOM_TEXT_MAX_TOKENS\n",
    "        if ob is None:\n",
    "            self.inst_verts[i] = None\n",
    "            return {\n",
    "                \"dom_simple_feats\": -torch.ones((1, DOM_MAX_VERTICES, 3), dtype=torch.float32),\n",
    "                \"dom_text_tokens\": torch.zeros((1, DOM_MAX_VERTICES, DOM_TEXT_MAX_TOKENS), dtype=torch.int64),\n",
    "                \"dom_tags\": torch.zeros((1, DOM_MAX_VERTICES), dtype=torch.int64),\n",
    "            }\n",
    "        else:\n",
    "            self.inst_verts[i] = ob.dom_elements\n",
    "            tokens = []\n",
    "            feats = []\n",
    "            tags_ = []\n",
    "            for elem in ob.dom_elements:\n",
    "                elem_text = elem.text if elem.text else \"\"\n",
    "                elem_tokens = self.tokenizer(elem_text,\n",
    "                                             padding='max_length',\n",
    "                                             max_length=DOM_TEXT_MAX_TOKENS,\n",
    "                                             truncation=True,\n",
    "                                             return_tensors=\"pt\")[\"input_ids\"]\n",
    "                tokens.append(elem_tokens)\n",
    "                elem_feats = torch.tensor([elem.focused, bool(elem.value), elem.tampered],\n",
    "                                          dtype=torch.float32)\n",
    "                feats.append(elem_feats)\n",
    "                tags_.append(torch.tensor([tag2id[elem.tag]], dtype=torch.int64))\n",
    "            \n",
    "            delta_v = DOM_MAX_VERTICES - len(tokens)\n",
    "            tokens += [torch.zeros((1, DOM_TEXT_MAX_TOKENS), dtype=torch.int64) for _ in range(delta_v)]\n",
    "            feats += [-torch.ones((3,), dtype=torch.float32) for _ in range(delta_v)]\n",
    "            tags_ += [torch.zeros((1,), dtype=torch.int64) for _ in range(delta_v)]\n",
    "            return{\n",
    "                \"dom_text_tokens\": torch.cat(tokens, dim=0).unsqueeze(0),\n",
    "                \"dom_simple_feats\": torch.stack(feats, dim=0).unsqueeze(0),\n",
    "                \"dom_tags\": torch.cat(tags_, dim=0).unsqueeze(0),\n",
    "            }\n",
    "    \n",
    "    def _ob_to_token(self, ob, i):\n",
    "        max_length = GOAL_MAX_TOKENS\n",
    "        if ob is None:\n",
    "            self.usernames[i] = \"\"\n",
    "            self.passwords[i] = \"\"\n",
    "            return torch.zeros(1, max_length)\n",
    "        else: \n",
    "            self.usernames[i] = ob.tokens[username_idx]\n",
    "            self.passwords[i] = ob.tokens[passwd_idx]\n",
    "            return self.tokenizer(ob.tokens,  \n",
    "                                  padding='max_length', \n",
    "                                  max_length = max_length, truncation=True,          \n",
    "                                  return_tensors=\"pt\",\n",
    "                                  is_split_into_words=True)['input_ids']\n",
    "            \n",
    "    def _ob_to_image(self, ob):\n",
    "        if ob is None:\n",
    "            return torch.zeros(1, 150, 150, 3)\n",
    "        else:\n",
    "            return torch.tensor(pil_to_numpy_array(ob.screenshot.resize([150, 150]))).unsqueeze(0)\n",
    "        \n",
    "    \n",
    "    def _to_miniwob_actions(self, actions):\n",
    "        \n",
    "        actions = actions.squeeze()\n",
    "        miniwob_actions = []\n",
    "        \n",
    "        for i in range(self.num_instances):\n",
    "            if self.instances[i].get_metadata()['done']:\n",
    "                miniwob_actions.append(None)\n",
    "            else:\n",
    "                if self.inst_verts[i] is None:\n",
    "                    miniwob_actions.append(None)\n",
    "                else:\n",
    "                    v_n = actions[i].item()\n",
    "                    if v_n == username_element_id and self.need_username[i]:\n",
    "                        text = self.usernames[i]\n",
    "                        element = self.inst_verts[i][username_element_id]\n",
    "                        miniwob_actions.append(MiniWoBFocusAndType(element, text))\n",
    "                        self.need_username[i] = False\n",
    "                    elif v_n == password_element_id and self.need_password[i]:\n",
    "                        text = self.passwords[i]\n",
    "                        element = self.inst_verts[i][password_element_id]\n",
    "                        miniwob_actions.append(MiniWoBFocusAndType(element, text))\n",
    "                        self.need_password[i] = False\n",
    "                    else:\n",
    "                        element = self.inst_verts[i][v_n]\n",
    "                        miniwob_actions.append(MiniWoBElementClick(element))\n",
    "        return miniwob_actions\n",
    "\n",
    "    def observation(self, obs):\n",
    "        goals = torch.cat([self._ob_to_token(obs[i], i) for i in range(len(obs))], dim=0)\n",
    "        imgs = torch.cat([self._ob_to_image(ob) for ob in obs], dim=0)\n",
    "        doms = [self._ob_to_dom(obs[i], i) for i in range(len(obs))]\n",
    "        doms_states = {key: torch.cat([dom[key] for dom in doms], dim=0) for key in self.dom_keys}\n",
    "        return {'img_state': imgs, 'goal_state': goals, **doms_states}\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.observation(self.env.reset(record_screenshots=True))\n",
    "    \n",
    "    def step(self, actions):\n",
    "        miniwob_actions = self._to_miniwob_actions(actions)\n",
    "        obs, rewards, dones, infos = self.env.step(miniwob_actions)        \n",
    "        obs = self.observation(obs)\n",
    "        \n",
    "        for i, instance in enumerate(self.env.instances):\n",
    "            if instance.get_metadata()['done']:\n",
    "                instance.begin_task()\n",
    "                self.need_username[i] = True\n",
    "                self.need_password[i] = True\n",
    "        \n",
    "        return obs, torch.tensor([rewards]).T, torch.tensor([dones]).T, infos['n']\n",
    "\n",
    "\n",
    "class EpisodeInfoWrapper(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env, n):\n",
    "        super(EpisodeInfoWrapper, self).__init__(env)\n",
    "        self.episode_reward = np.zeros(n)\n",
    "        self.episode_steps = np.zeros(n)\n",
    "        self.n = n\n",
    "\n",
    "    def reset(self):\n",
    "        self.episode_reward = np.zeros(self.n)\n",
    "        self.episode_steps = np.zeros(self.n)\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, actions):\n",
    "        states, rewards, dones, infos = self.env.step(actions)\n",
    "        \n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                self.episode_reward[i] = rewards[i]\n",
    "                self.episode_steps[i] += 1\n",
    "                infos[i]['episode'] = {'r': self.episode_reward[i], 'steps': self.episode_steps[i]}\n",
    "                \n",
    "        return states, rewards, dones, infos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import relu\n",
    "import torch\n",
    "\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        bert_model = 'bert-base-cased'\n",
    "        \n",
    "        self.bert_encoder = BertModel.from_pretrained(bert_model)\n",
    "        self.embed_dim = 768\n",
    "        self.output_size = 64\n",
    "        #self.out_layer = nn.Linear(self.embed_dim, self.output_size)\n",
    "        self.out_layer = nn.AdaptiveAvgPool1d(output_size=self.output_size)\n",
    "        tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        self.pad_token = tokenizer.pad_token_id\n",
    "   \n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Encode batch of tokens\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            text_tokens_embed = self.bert_encoder(input_ids.long())[0]\n",
    "            out = self.out_layer(text_tokens_embed)\n",
    "            #out = relu(self.out_layer(text_tokens_embed))\n",
    "        \n",
    "        pad_mask = torch.where(input_ids.long() == self.pad_token, True, False)\n",
    "        return out, pad_mask\n",
    "\n",
    "\n",
    "class DOMBert(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        bert_model = 'bert-base-cased'\n",
    "        \n",
    "        self.bert_encoder = BertModel.from_pretrained(bert_model)\n",
    "        self.embed_dim = 768\n",
    "        self.output_size = 64 - 7\n",
    "        #self.out_layer = nn.Linear(self.embed_dim, self.output_size)\n",
    "        self.out_layer = nn.AdaptiveAvgPool1d(output_size=self.output_size)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Encode batch of tokens\n",
    "        \n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            text_tokens_embed = self.bert_encoder(input_ids.long())[1]\n",
    "            out = self.out_layer(text_tokens_embed)\n",
    "        #out = relu(self.out_layer(text_tokens_embed))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import ModuleList, Parameter, TransformerEncoderLayer, TransformerEncoder\n",
    "from torch.nn.functional import relu, softmax\n",
    "\n",
    "\n",
    "UNDIRECTED = True\n",
    "SELF_LOOP = True\n",
    "bert_model = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "\n",
    "class DOMEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOMEncoder, self).__init__()\n",
    "        self.inp_dim = 64\n",
    "        self.output_size = 64\n",
    "        self.h_dim = 64\n",
    "        self.n_h_layers = 1\n",
    "        \n",
    "        self.layers = ModuleList([nn.Linear(self.inp_dim, self.h_dim)] + \\\n",
    "                                 [nn.Linear(self.h_dim, self.h_dim) for _ in range(self.n_h_layers)] + \\\n",
    "                                 [nn.Linear(self.h_dim, self.output_size)])\n",
    "        \n",
    "        self.bn = nn.ModuleList([nn.BatchNorm1d(self.inp_dim)] + \\\n",
    "                                [nn.BatchNorm1d(self.h_dim) for _ in range(self.n_h_layers + 1)])\n",
    "        \n",
    "        self.text_encoder = DOMBert()\n",
    "        self.tag_vectorizer = nn.Embedding(len(tags), 4)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        mask = input[\"dom_simple_feats\"][:, :, 0] # B x MAX_VERTS\n",
    "        mask = torch.where(mask==-1, True, False)\n",
    "        \n",
    "        tokens = input[\"dom_text_tokens\"]\n",
    "        bs = tokens.shape[0]\n",
    "        tokens = torch.flatten(tokens, end_dim=-2) # B*MAX_VERTS x MAX_TOKENS\n",
    "        text_feats = self.text_encoder(tokens)\n",
    "        \n",
    "        tag_feats = self.tag_vectorizer(input[\"dom_tags\"].long())\n",
    "        tag_feats = torch.flatten(tag_feats, end_dim=-2)   # B*MAX_VERTS x DIM_t\n",
    "        \n",
    "        feats = torch.flatten(input[\"dom_simple_feats\"], end_dim=-2) # B*MAX_VERTS x DIM_f\n",
    "        feats = torch.cat([text_feats, tag_feats, feats], dim=-1)\n",
    "        \n",
    "        out = feats\n",
    "        prev = feats\n",
    "        for l, b in zip(self.layers, self.bn):\n",
    "            out = b(out)\n",
    "            out = l(out)\n",
    "            out = F.relu(out)\n",
    "            out = out + prev\n",
    "            prev = out\n",
    "        out = out.view(bs, DOM_MAX_VERTICES, -1).permute([1, 0, 2]) # MAX_VERTS x B x DIM\n",
    "        return out, mask\n",
    "\n",
    "\n",
    "class DOMGoalTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOMGoalTransformer, self).__init__()\n",
    "        self.inp_dim = 64\n",
    "        self.output_size = self.inp_dim\n",
    "        \n",
    "        self.embed_token = nn.Parameter(torch.empty(1, 1, self.inp_dim))\n",
    "        nn.init.uniform_(self.embed_token, -0.2, 0.2)\n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(64, 4, dim_feedforward=64, norm_first=True)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, 4)\n",
    "    \n",
    "    def forward(self, inp, mask):\n",
    "        mask = torch.cat([torch.zeros_like(mask[:, :1], dtype=torch.bool), mask], dim=1)\n",
    "        inp = torch.cat([self.embed_token.repeat_interleave(inp.shape[1], dim=1), inp], dim=0)\n",
    "        out = self.encoder(inp, src_key_padding_mask=mask)\n",
    "        return out[0]\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dom = DOMEncoder()\n",
    "        self.goal = BertEncoder()\n",
    "        self.tf = DOMGoalTransformer()\n",
    "        self.output_size = 64\n",
    "    \n",
    "    def forward(self, input):\n",
    "        dom_embeds, dom_mask = self.dom(input)\n",
    "        goal_embeds, goal_mask = self.goal(input[\"goal_state\"])\n",
    "        dom_goal_embeds = torch.cat([dom_embeds, goal_embeds.permute([1, 0, 2])], dim=0)\n",
    "        dom_goal_mask = torch.cat([dom_mask, goal_mask], dim=1)\n",
    "        out = self.tf(dom_goal_embeds, dom_goal_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rllr.models.ppo import FixedCategorical, ActorCriticNetwork, CriticNetwork\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class DiscreteActorNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor is a policy network. Given state it evaluates\n",
    "    probability of action given state or sample an action\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_size, state_encoder, vertex_encoder, hidden_size):\n",
    "        super().__init__()\n",
    "        self.cos = nn.CosineSimilarity(dim=-1)\n",
    "        self.state_encoder = state_encoder\n",
    "        self.vertex_encoder = vertex_encoder\n",
    "        input_size = state_encoder.output_size\n",
    "        fc_layers = []\n",
    "        if type(hidden_size) == int:\n",
    "            fc_layers += [\n",
    "                nn.Linear(input_size, hidden_size),\n",
    "                nn.ReLU(inplace=False),\n",
    "                nn.Linear(hidden_size, input_size)\n",
    "            ]\n",
    "        elif type(hidden_size) == list:\n",
    "            for hs in hidden_size:\n",
    "                fc_layers.append(nn.Linear(input_size, hs))\n",
    "                fc_layers.append(nn.ReLU(inplace=False))\n",
    "                input_size = hs\n",
    "            fc_layers.append(nn.Linear(input_size, action_size))\n",
    "        else:\n",
    "            AttributeError(f\"unknown type of {hidden_size} parameter\")\n",
    "\n",
    "        self.logits = nn.Sequential(*fc_layers)\n",
    "        self.output_size = action_size\n",
    "\n",
    "    def forward(self, states):\n",
    "        states_encoding = self.state_encoder(states)\n",
    "        states_encoding = self.logits(states_encoding) # BxH\n",
    "        vertex_encoding, vertex_mask = self.vertex_encoder(states)  # VxBxH ; BxV\n",
    "        \n",
    "        if vertex_encoding.shape[0] == 0:\n",
    "            return FixedCategorical(logits=F.log_softmax(torch.zeros((vertex_encoding.shape[1], 2)), dim=1))\n",
    "        \n",
    "        #logits = torch.matmul(vertex_encoding.permute([1,0,2]), states_encoding.unsqueeze(-1)).squeeze(-1) #BxV\n",
    "        logits = self.cos(vertex_encoding.permute([1,0,2]), states_encoding.unsqueeze(1))\n",
    "        logits = logits * torch.pi / 2\n",
    "        logits = torch.clamp(logits, -torch.pi/2+1e-6, torch.pi/2-1e-6)\n",
    "        logits = torch.tan(logits)\n",
    "        \n",
    "        for i, m in enumerate(vertex_mask):\n",
    "            if m.all():\n",
    "                vertex_mask[i] = torch.zeros_like(m, dtype=torch.bool)\n",
    "        \n",
    "        logits = torch.where(vertex_mask, -float(\"inf\"), logits.double())\n",
    "        return FixedCategorical(logits=F.log_softmax(logits, dim=1))\n",
    "\n",
    "\n",
    "class ACN(ActorCriticNetwork):\n",
    "    def __init__(self, action_space, actor_state_encoder, actor_vertex_encoder, critic_state_encoder, actor_hidden_size, critic_hidden_size):\n",
    "        super(ActorCriticNetwork, self).__init__()\n",
    "        if type(action_space) == gym.spaces.Discrete:\n",
    "            self.actor = DiscreteActorNetwork(action_space.n, actor_state_encoder, actor_vertex_encoder, actor_hidden_size)\n",
    "        else:\n",
    "            raise f'{action_space} not supported'\n",
    "        self.critic = CriticNetwork(critic_state_encoder, critic_hidden_size)\n",
    "\n",
    "        def init_params(m):\n",
    "            classname = m.__class__.__name__\n",
    "            if classname.find(\"Linear\") != -1:\n",
    "                m.weight.data.normal_(0, 1)\n",
    "                m.weight.data *= 1 / torch.sqrt(m.weight.data.pow(2).sum(1, keepdim=True))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0)\n",
    "\n",
    "        self.apply(init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rllr.env.vec_wrappers import make_vec_envs\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "def get_envs(n, **kwargs):\n",
    "    env = MiniWoBEnvironment(task_name, seeds=range(n), num_instances=n, base_url=base_url, **kwargs)\n",
    "    env = MiniWobClickElementWrapper(env)\n",
    "    return EpisodeInfoWrapper(env, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_instances = 4\n",
    "envs = get_envs(n_instances, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from rllr.models.encoders import GoalStateEncoder, SimpleCNN\n",
    "\n",
    "conf = {\n",
    "    \"n_channels\": [32, 64, 64],\n",
    "    \"kernel_sizes\": [4, 4, 3],\n",
    "    \"strides\": [4, 2, 1],\n",
    "    \"hidden_layers_sizes\": [64]\n",
    "}\n",
    "\n",
    "actor_vertex_encoder = DOMEncoder()\n",
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rllr.algo.ppo.PPO at 0x7f16f0bfc850>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rllr.algo import PPO\n",
    "from rllr.models.ppo import ActorCriticNetwork\n",
    "\n",
    "hidden_size = 32\n",
    "policy = ACN(envs.action_space, encoder, actor_vertex_encoder, encoder, hidden_size, hidden_size)\n",
    "\n",
    "agent_conf = {\n",
    "        \"clip_param\": 0.2,\n",
    "        \"ppo_epoch\": 4,\n",
    "        \"num_mini_batch\": 4,\n",
    "        \"value_loss_coef\": 0.5,\n",
    "        \"entropy_coef\": 0.01,\n",
    "        \"lr\": 0.001,\n",
    "        \"eps\": 1e-5,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "}\n",
    "\n",
    "\n",
    "agent = PPO(policy, **agent_conf)\n",
    "agent.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rllr.utils import train_ppo\n",
    "\n",
    "\n",
    "train_conf = {\n",
    "    \"agent.lr\": 0.001,\n",
    "    \"agent.device\": device,\n",
    "    \"agent.gamma\": 0.99,\n",
    "    \"agent.gae_lambda\": 0.95,\n",
    "    \"training.n_env_steps\": 400000,\n",
    "    \"training.n_steps\": 50,\n",
    "    \"training.n_processes\": n_instances,\n",
    "    \"training.verbose\": 1,\n",
    "    \"outputs.path\": \"exp_three/miniwob_element_click_exp_three\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ppo(envs, agent, train_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
