{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "chrome_driver_path = os.path.join(\"/\", 'home', 'morlov', 'chromedriver')\n",
    "# os.path.join(\"/\", 'usr', 'local', 'bin', 'chromedriver') local\n",
    "os.environ[\"PATH\"] += os.pathsep + chrome_driver_path\n",
    "os.environ[\"MINIWOB_BASE_URL\"] = \"file:///mnt/morlov/miniwob-plusplus/html/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: file:///mnt/morlov/miniwob-plusplus/html/\n"
     ]
    }
   ],
   "source": [
    "from miniwob.environment import MiniWoBEnvironment\n",
    "from miniwob.action import  MiniWoBCoordClick\n",
    "from miniwob.screenshot import pil_to_numpy_array\n",
    "\n",
    "task_name = 'click-button'\n",
    "base_url = os.environ.get('MINIWOB_BASE_URL')\n",
    "env = MiniWoBEnvironment(task_name, seeds=[1, 2, 3], num_instances=3, base_url=base_url, headless=True)\n",
    "print('BASE URL:', base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.reset(record_screenshots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MiniWoBState(utterance: 'Click on the \"Ok\" button.'),\n",
       " MiniWoBState(utterance: 'Click on the \"ok\" button.'),\n",
       " MiniWoBState(utterance: 'Click on the \"no\" button.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x210 at 0x7F591C23FC70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0].screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = pil_to_numpy_array(states[0].screenshot)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"- [1] body @ (0, 0) classes=[NO_CLASS] children=1\\n  |- [2] div @ (0, 0) classes=[NO_CLASS] children=1\\n     |- [3] div @ (0, 50) classes=[NO_CLASS] children=6\\n        |- [4] div @ (2, 52) text='cursus dis justo' classes=[NO_CLASS]\\n        |- [5] div @ (2, 63) text='facilisis proin aliq...' classes=[NO_CLASS]\\n        |- [6] button @ (2, 74) text='Ok' classes=[NO_CLASS]\\n        |- [7] div @ (2, 95) text='pharetra turpis scel...' classes=[NO_CLASS]\\n        |- [8] div @ (2, 106) text='rutrum lectus adipis...' classes=[NO_CLASS]\\n        |- [9] div @ (2, 117) text='pretium, aliquet ege...' classes=[NO_CLASS]\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0].dom.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Click', 'on', 'the', '\"', 'Ok', '\"', 'button', '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f591d7a9ca0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b87d840736b25b83b8a95106db156729\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f591c23fb80>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/1c69efe00a0d19473d018982393f1c25\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f597871fac0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/036025a18c277316357bf0c4e1b3d167\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f591d7a9af0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b87d840736b25b83b8a95106db156729\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f597871f3d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/1c69efe00a0d19473d018982393f1c25\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f597871f130>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/036025a18c277316357bf0c4e1b3d167\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f597871fcd0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b87d840736b25b83b8a95106db156729\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f597871fd60>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/1c69efe00a0d19473d018982393f1c25\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f597871fdf0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/036025a18c277316357bf0c4e1b3d167\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym miniwob wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from miniwob.action import MiniWoBElementClick, MiniWoBCoordClick\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "\n",
    "class MiniWobClickButtonWrapper(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env):      \n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        bert_model = 'bert-base-cased'\n",
    "        code_bert_model = \"microsoft/codebert-base\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        self.n_tokens_goal = 8\n",
    "        self.n_tokens_dom = 128\n",
    "        self.dom_tokenizer = RobertaTokenizer.from_pretrained(code_bert_model)\n",
    "        \n",
    "        self.observation_space = gym.spaces.Dict({\"goal_state\": gym.spaces.Box(0, \n",
    "                                                                              self.tokenizer.vocab_size, \n",
    "                                                                              (self.n_tokens_goal, ),\n",
    "                                                                              dtype=np.int64), \n",
    "                                                  \"dom_state\": gym.spaces.Box(0,\n",
    "                                                                        self.dom_tokenizer.vocab_size,\n",
    "                                                                        (self.n_tokens_dom, ), \n",
    "                                                                              dtype=np.int64),\n",
    "                                                  \"img_state\": gym.spaces.Box(0, 255, (210, 160, 3), dtype=np.uint8)})\n",
    "        \n",
    "\n",
    "        self.h, self.w = 210, 160\n",
    "        self.grid_step = 10\n",
    "        n_actions = int(self.h/self.grid_step+1) * int(self.w/self.grid_step+1)\n",
    "        self.action_space = gym.spaces.Discrete(n_actions)\n",
    "        \n",
    "    def _ob_to_token(self, ob):\n",
    "        if ob is None:\n",
    "            return torch.zeros(1, self.n_tokens_goal)\n",
    "        else: \n",
    "            return self.tokenizer(ob.tokens,  \n",
    "                                  padding='max_length', \n",
    "                                  max_length = self.n_tokens_goal, truncation=True,          \n",
    "                                  return_tensors=\"pt\",\n",
    "                                  is_split_into_words=True)['input_ids']\n",
    "        \n",
    "    def _ob_dom_to_token(self, ob):\n",
    "        if ob is None:\n",
    "            return torch.zeros(1, self.n_tokens_dom)\n",
    "        else: \n",
    "            dom = self.dom_tokenizer.tokenize(obs.dom.visualize())[:16]\n",
    "            dom_str = \"website DOM-tree\"\n",
    "            dom_str_tokens = self.dom_tokenizer.tokenize(dom_str)\n",
    "            dom = [self.dom_tokenizer.cls_token] + dom_str_tokens + [self.dom_tokenizer.sep_token] \\\n",
    "                  + dom + [self.dom_tokenizer.sep_token] + [self.dom_tokenizer.pad_token] * self.n_tokens_dom\n",
    "            dom = self.dom_tokenizer.convert_tokens_to_ids(dom[:self.n_tokens_dom])\n",
    "            dom = torch.tensor(dom, dtype=torch.int64).unsqueeze(0)\n",
    "            return dom\n",
    "            \n",
    "    def _ob_to_image(self, ob):\n",
    "        if ob is None:\n",
    "            return torch.zeros(1, self.h, self.w, 3)\n",
    "        else:\n",
    "            return torch.tensor(pil_to_numpy_array(ob.screenshot)).unsqueeze(0)\n",
    "        \n",
    "    \n",
    "    def _to_miniwob_actions(self, actions):\n",
    "        \n",
    "        n_x = int(self.w/self.grid_step + 1)        \n",
    "        actions = actions.squeeze()\n",
    "        miniwob_actions = []\n",
    "        \n",
    "        for i in range(self.num_instances):\n",
    "            if self.instances[i].get_metadata()['done']:\n",
    "                miniwob_actions.append(None)\n",
    "            else:\n",
    "                k = actions[i].item()\n",
    "                x, y = k%n_x * self.grid_step, int(k/n_x) * self.grid_step\n",
    "                miniwob_actions.append(MiniWoBCoordClick(x, y))\n",
    "        return miniwob_actions\n",
    "        \n",
    "    \n",
    "    def observation(self, obs):\n",
    "            \n",
    "        goals = torch.cat([self._ob_to_token(ob) for ob in obs], dim=0).to(device)\n",
    "        doms = torch.cat([self._ob_dom_to_token(ob) for ob in obs], dim=0).to(device)\n",
    "        imgs = torch.cat([self._ob_to_image(ob) for ob in obs], dim=0).to(device)\n",
    "        return {\"img_state\": imgs, 'dom_state': dom, 'goal_state': goals}\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.observation(self.env.reset(record_screenshots=True))\n",
    "    \n",
    "            \n",
    "    \n",
    "    def step(self, actions):\n",
    "        \n",
    "        miniwob_actions = self._to_miniwob_actions(actions)\n",
    "        obs, rewards, dones, infos = self.env.step(miniwob_actions)        \n",
    "        obs = self.observation(obs)\n",
    "        \n",
    "        for instance in self.env.instances:\n",
    "            if instance.get_metadata()['done']:\n",
    "                instance.begin_task()\n",
    "        \n",
    "        return obs, torch.tensor([rewards]).T, torch.tensor([dones]).T, infos['n']\n",
    "        \n",
    "class EpisodeInfoWrapper(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env, n):\n",
    "        super(EpisodeInfoWrapper, self).__init__(env)\n",
    "        self.episode_reward = np.zeros(n)\n",
    "        self.episode_steps = np.zeros(n)\n",
    "        self.n = n\n",
    "\n",
    "    def reset(self):\n",
    "        self.episode_reward = np.zeros(self.n)\n",
    "        self.episode_steps = np.zeros(self.n)\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, actions):\n",
    "        states, rewards, dones, infos = self.env.step(actions)\n",
    "        \n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                self.episode_reward[i] = rewards[i]\n",
    "                self.episode_steps[i] += 1\n",
    "                infos[i]['episode'] = {'r': self.episode_reward[i], 'steps': self.episode_steps[i]}\n",
    "                \n",
    "        return states, rewards, dones, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_envs(n, **kwargs):\n",
    "    env = MiniWoBEnvironment(task_name, seeds=range(n), num_instances=n, base_url=base_url, **kwargs)\n",
    "    env = MiniWobClickButtonWrapper(env)\n",
    "    return EpisodeInfoWrapper(env, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        bert_model = 'bert-base-cased'\n",
    "        self.bert_encoder = BertModel.from_pretrained(bert_model).to(device)\n",
    "        self.embed_dim = 768\n",
    "        output_size = 100\n",
    "        self.lstm = nn.LSTM(input_size=self.embed_dim, \n",
    "                            hidden_size=output_size, \n",
    "                            num_layers=2)\n",
    "        self.hidden_size = 128\n",
    "        in_size = output_size\n",
    "        out_size = self.hidden_size\n",
    "        self.fc = nn.Sequential(nn.Linear(in_size, out_size), nn.ReLU())\n",
    "        self.output_size = out_size\n",
    "   \n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Encode batch of tokens\n",
    "        \n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            embeds = self.bert_encoder(input_ids.long()).last_hidden_state\n",
    "        embeds = embeds.permute([1, 0, 2])\n",
    "            \n",
    "        output, _ = self.lstm(embeds)\n",
    "        return self.fc(output[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as zoo_models\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = zoo_models.resnet34(pretrained=True)\n",
    "        self.output_size = 32\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        in_size, out_size = 512, self.output_size\n",
    "        self.fc = nn.Sequential(nn.Linear(in_size, out_size), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        with torch.no_grad():\n",
    "            encoded = self.resnet(x).reshape(x.shape[0], -1)\n",
    "        return self.fc(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Permute(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.dims = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.permute(self.dims)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, h, w, conf):\n",
    "        super().__init__()\n",
    "        conv_layers = [Permute(0, 3, 1, 2)]\n",
    "        cnn_output_h, cnn_output_w = h, w\n",
    "        cur_channels = 3\n",
    "        conv_params = zip(\n",
    "            conf['n_channels'],\n",
    "            conf['kernel_sizes'],\n",
    "            conf['max_pools'] if conf.get('max_pools', False) else [1] * len(conf['n_channels']),\n",
    "            conf['strides'] if conf.get('strides', False) else [1] * len(conf['n_channels'])\n",
    "        )\n",
    "        for n_channels, kernel_size, max_pool, stride in conv_params:\n",
    "            conv_layers.append(nn.Conv2d(cur_channels, n_channels, kernel_size, stride))\n",
    "            conv_layers.append(nn.ReLU(inplace=True))\n",
    "            cnn_output_h += -1 * kernel_size + stride\n",
    "            cnn_output_w += -1 * kernel_size + stride\n",
    "            cnn_output_h //= stride\n",
    "            cnn_output_w //= stride\n",
    "            cur_channels = n_channels\n",
    "            if max_pool > 1:\n",
    "                conv_layers.append(nn.MaxPool2d(max_pool, max_pool))\n",
    "                cnn_output_h //= max_pool\n",
    "                cnn_output_w //= max_pool\n",
    "        self.conv_net = nn.Sequential(*conv_layers)\n",
    "        output_size = cur_channels * cnn_output_h * cnn_output_w\n",
    "\n",
    "        hidden_layers_sizes = list(conf.get('hidden_layers_sizes', []))\n",
    "        if hidden_layers_sizes:\n",
    "            fc_layers = []\n",
    "            layers_size = [output_size] + hidden_layers_sizes\n",
    "            for size_in, size_out in zip(layers_size[:-1], layers_size[1:]):\n",
    "                fc_layers.append(nn.Linear(size_in, size_out))\n",
    "                fc_layers.append(nn.ReLU())\n",
    "            self.fc = nn.Sequential(*fc_layers)\n",
    "            output_size = layers_size[-1]\n",
    "        else:\n",
    "            self.fc = None\n",
    "\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.conv_net(x.float() / 255.).reshape(x.shape[0], -1)\n",
    "        if self.fc is not None:\n",
    "            res = self.fc(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dom encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert_encoder = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "        self.embed_dim = 768\n",
    "        self.output_size = 100\n",
    "        self.lstm = nn.LSTM(input_size=self.embed_dim,\n",
    "                            hidden_size=self.output_size, \n",
    "                            num_layers=2)\n",
    "        self.hidden_size = 128\n",
    "        in_size = output_size\n",
    "        out_size = self.hidden_size\n",
    "        self.fc = nn.Sequential(nn.Linear(in_size, out_size), nn.ReLU())\n",
    "        self.output_size = out_size\n",
    "        \n",
    "   \n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Encode batch of tokens\n",
    "        \n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            embeds = self.bert_encoder(input_ids.long()).last_hidden_state\n",
    "        embeds = embeds.permute([1, 0, 2])\n",
    "            \n",
    "        output, _ = self.lstm(embeds)\n",
    "        return self.fc(output[-1])\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img, dom):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.img_encoder = img\n",
    "        self.dom_encoder = dom\n",
    "        self.output_size = self.dom_encoder.output_size + self.img_encoder.output_size\n",
    "    \n",
    "    def forward(self, ob):\n",
    "        img_out = self.img_encoder(ob['img'])\n",
    "        dom_out = self.dom_encoder(ob['dom'])\n",
    "        out = torch.cat([img_out, dom_out], dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from rllr.models.encoders import GoalStateEncoder # , SimpleCNN\n",
    "\n",
    "conf = {\n",
    "    \"n_channels\": [32, 32, 32, 32, 32, 32],\n",
    "    \"kernel_sizes\": [4, 4, 4, 4, 4, 4],\n",
    "    \"strides\": [4, 2, 1, 1, 1, 1],\n",
    "    \"hidden_layers_sizes\": [128]\n",
    "}\n",
    "\n",
    "state_encoder = SimpleCNN(h=210, w=160, conf=conf).to(device)\n",
    "goal_encoder = BertEncoder().to(device)\n",
    "dom_encoder = DomEncoder().to(device)\n",
    "state_encoder = Encoder(img_encoder, dom_encoder).to(device)\n",
    "goal_encoder = BertEncoder().to(device)\n",
    "encoder = GoalStateEncoder(state_encoder, goal_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = 16\n",
    "envs = get_envs(n_instances, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rllr.algo import PPO\n",
    "from rllr.models.ppo import ActorCriticNetwork\n",
    "\n",
    "hidden_size = 32\n",
    "policy = ActorCriticNetwork(envs.action_space, encoder, encoder, hidden_size, hidden_size).to(device)\n",
    "\n",
    "agent_conf = {\n",
    "        \"clip_param\": 0.2,\n",
    "        \"ppo_epoch\": 4,\n",
    "        \"num_mini_batch\": 4,\n",
    "        \"value_loss_coef\": 0.5,\n",
    "        \"entropy_coef\": 0.01,\n",
    "        \"lr\": 0.001,\n",
    "        \"eps\": 1e-5,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "}\n",
    "\n",
    "\n",
    "agent = PPO(policy, **agent_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = torch.load(\"miniwob_click_button.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 0, num timesteps 1600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.33/-0.49, min/max reward -1.00/0.90\n",
      "dist_entropy 5.92, value_loss 0.09, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/62 [01:00<1:01:48, 60.79s/it]WARNING:root:Cannot call CoordClick(coords: (90, 10)) on instance 1, which is already done\n",
      "  3%|▎         | 2/62 [02:01<1:00:37, 60.62s/it]WARNING:root:Cannot call CoordClick(coords: (130, 180)) on instance 7, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (50, 130)) on instance 2, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (160, 0)) on instance 8, which is already done\n",
      "  5%|▍         | 3/62 [03:01<59:22, 60.37s/it]  WARNING:root:Cannot call CoordClick(coords: (90, 20)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (140, 70)) on instance 10, which is already done\n",
      "  8%|▊         | 5/62 [05:01<57:13, 60.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 5, num timesteps 9600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward 0.03/0.36, min/max reward -1.00/0.96\n",
      "dist_entropy 5.84, value_loss 0.10, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 6/62 [06:02<56:25, 60.46s/it]WARNING:root:Cannot call CoordClick(coords: (120, 160)) on instance 1, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (80, 190)) on instance 6, which is already done\n",
      " 11%|█▏        | 7/62 [07:02<55:17, 60.32s/it]WARNING:root:Cannot call CoordClick(coords: (160, 90)) on instance 1, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (150, 20)) on instance 7, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (60, 80)) on instance 1, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (110, 20)) on instance 2, which is already done\n",
      " 16%|█▌        | 10/62 [10:02<52:09, 60.17s/it]WARNING:root:Cannot call CoordClick(coords: (110, 20)) on instance 2, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (120, 120)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (80, 10)) on instance 1, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (130, 150)) on instance 6, which is already done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 10, num timesteps 17600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.81/-1.00, min/max reward -1.00/0.90\n",
      "dist_entropy 5.76, value_loss 0.10, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 11/62 [11:03<51:18, 60.35s/it]WARNING:root:Cannot call CoordClick(coords: (60, 180)) on instance 5, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (90, 120)) on instance 4, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (40, 80)) on instance 6, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (160, 80)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (160, 200)) on instance 9, which is already done\n",
      " 19%|█▉        | 12/62 [12:03<50:09, 60.18s/it]WARNING:root:Cannot call CoordClick(coords: (100, 150)) on instance 7, which is already done\n",
      " 23%|██▎       | 14/62 [14:03<48:03, 60.08s/it]WARNING:root:Cannot call CoordClick(coords: (130, 10)) on instance 4, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (0, 80)) on instance 5, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (160, 210)) on instance 3, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (80, 40)) on instance 9, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (30, 190)) on instance 7, which is already done\n",
      " 24%|██▍       | 15/62 [15:03<47:04, 60.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 15, num timesteps 25600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.21/-0.43, min/max reward -1.00/0.90\n",
      "dist_entropy 5.66, value_loss 0.11, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 17/62 [17:04<45:15, 60.35s/it]WARNING:root:Cannot call CoordClick(coords: (140, 100)) on instance 3, which is already done\n",
      " 29%|██▉       | 18/62 [18:04<44:16, 60.38s/it]WARNING:root:Cannot call CoordClick(coords: (120, 130)) on instance 6, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (0, 0)) on instance 2, which is already done\n",
      " 32%|███▏      | 20/62 [20:05<42:08, 60.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 20, num timesteps 33600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward 0.14/0.40, min/max reward -1.00/0.91\n",
      "dist_entropy 5.47, value_loss 0.10, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 21/62 [21:06<41:17, 60.43s/it]WARNING:root:Cannot call CoordClick(coords: (130, 70)) on instance 0, which is already done\n",
      " 35%|███▌      | 22/62 [22:06<40:15, 60.40s/it]WARNING:root:Cannot call CoordClick(coords: (70, 130)) on instance 6, which is already done\n",
      " 37%|███▋      | 23/62 [23:06<39:08, 60.21s/it]WARNING:root:Cannot call CoordClick(coords: (160, 140)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (30, 210)) on instance 1, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (0, 20)) on instance 14, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (30, 10)) on instance 13, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (60, 170)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (150, 30)) on instance 5, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (60, 150)) on instance 1, which is already done\n",
      " 40%|████      | 25/62 [25:06<37:06, 60.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 25, num timesteps 41600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.05/0.46, min/max reward -1.00/0.77\n",
      "dist_entropy 5.47, value_loss 0.10, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 27/62 [27:08<35:20, 60.59s/it]WARNING:root:Cannot call CoordClick(coords: (60, 110)) on instance 11, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (120, 40)) on instance 4, which is already done\n",
      " 45%|████▌     | 28/62 [28:08<34:14, 60.43s/it]WARNING:root:Cannot call CoordClick(coords: (20, 130)) on instance 4, which is already done\n",
      " 47%|████▋     | 29/62 [29:09<33:17, 60.52s/it]WARNING:root:Cannot call CoordClick(coords: (140, 40)) on instance 6, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (130, 140)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (120, 40)) on instance 3, which is already done\n",
      " 48%|████▊     | 30/62 [30:09<32:15, 60.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 30, num timesteps 49600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.38/-1.00, min/max reward -1.00/0.90\n",
      "dist_entropy 5.63, value_loss 0.08, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 32/62 [32:11<30:21, 60.71s/it]WARNING:root:Cannot call CoordClick(coords: (60, 90)) on instance 5, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (120, 200)) on instance 7, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (70, 190)) on instance 9, which is already done\n",
      " 53%|█████▎    | 33/62 [33:13<29:32, 61.14s/it]WARNING:root:Cannot call CoordClick(coords: (150, 200)) on instance 14, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (90, 30)) on instance 2, which is already done\n",
      " 55%|█████▍    | 34/62 [34:14<28:33, 61.18s/it]WARNING:root:Cannot call CoordClick(coords: (40, 140)) on instance 7, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (140, 100)) on instance 11, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (130, 140)) on instance 9, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (140, 30)) on instance 1, which is already done\n",
      " 56%|█████▋    | 35/62 [35:15<27:27, 61.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 35, num timesteps 57600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.13/-0.33, min/max reward -1.00/0.96\n",
      "dist_entropy 5.64, value_loss 0.10, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 37/62 [37:17<25:22, 60.89s/it]WARNING:root:Cannot call CoordClick(coords: (100, 30)) on instance 2, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (10, 140)) on instance 4, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (100, 180)) on instance 8, which is already done\n",
      " 61%|██████▏   | 38/62 [38:17<24:19, 60.82s/it]WARNING:root:Cannot call CoordClick(coords: (50, 190)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (90, 170)) on instance 0, which is already done\n",
      " 63%|██████▎   | 39/62 [39:18<23:17, 60.77s/it]WARNING:root:Cannot call CoordClick(coords: (80, 50)) on instance 0, which is already done\n",
      " 65%|██████▍   | 40/62 [40:19<22:16, 60.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 40, num timesteps 65600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward 0.10/0.73, min/max reward -1.00/0.96\n",
      "dist_entropy 5.60, value_loss 0.12, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 44/62 [44:22<18:12, 60.68s/it]WARNING:root:Cannot call CoordClick(coords: (0, 60)) on instance 3, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (120, 30)) on instance 4, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (100, 10)) on instance 7, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (90, 100)) on instance 1, which is already done\n",
      " 73%|███████▎  | 45/62 [45:23<17:11, 60.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 45, num timesteps 73600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.19/-0.49, min/max reward -1.00/0.96\n",
      "dist_entropy 5.51, value_loss 0.11, action_loss -0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 47/62 [47:25<15:11, 60.77s/it]WARNING:root:Cannot call CoordClick(coords: (160, 180)) on instance 0, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (90, 70)) on instance 10, which is already done\n",
      " 81%|████████  | 50/62 [50:26<12:07, 60.61s/it]WARNING:root:Cannot call CoordClick(coords: (140, 180)) on instance 1, which is already done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 50, num timesteps 81600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.02/0.31, min/max reward -1.00/0.96\n",
      "dist_entropy 5.55, value_loss 0.12, action_loss -0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 52/62 [52:28<10:06, 60.67s/it]WARNING:root:Cannot call CoordClick(coords: (20, 20)) on instance 11, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (90, 130)) on instance 2, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (30, 170)) on instance 3, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (100, 30)) on instance 8, which is already done\n",
      " 85%|████████▌ | 53/62 [53:28<09:04, 60.46s/it]WARNING:root:Cannot call CoordClick(coords: (50, 130)) on instance 5, which is already done\n",
      " 89%|████████▊ | 55/62 [55:28<07:01, 60.25s/it]WARNING:root:Cannot call CoordClick(coords: (50, 70)) on instance 2, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (10, 80)) on instance 6, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (10, 190)) on instance 1, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (10, 10)) on instance 8, which is already done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 55, num timesteps 89600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.65/-1.00, min/max reward -1.00/0.30\n",
      "dist_entropy 5.57, value_loss 0.10, action_loss -0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 58/62 [58:29<04:01, 60.34s/it]WARNING:root:Cannot call CoordClick(coords: (140, 200)) on instance 1, which is already done\n",
      " 95%|█████████▌| 59/62 [59:30<03:01, 60.47s/it]WARNING:root:Cannot call CoordClick(coords: (10, 50)) on instance 6, which is already done\n",
      "WARNING:root:Cannot call CoordClick(coords: (80, 190)) on instance 1, which is already done\n",
      " 97%|█████████▋| 60/62 [1:00:30<02:00, 60.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 60, num timesteps 97600, FPS 26 \n",
      "Last 10 training episodes: mean/median reward -0.09/-0.16, min/max reward -1.00/0.90\n",
      "dist_entropy 5.54, value_loss 0.13, action_loss -0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [1:02:31<00:00, 60.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from rllr.utils.training import train_ppo\n",
    "\n",
    "train_conf = {\n",
    "    \"agent.lr\": 0.001,\n",
    "    \"agent.device\": device,\n",
    "    \"agent.gamma\": 0.99,\n",
    "    \"agent.gae_lambda\": 0.95,\n",
    "    \"training.n_env_steps\": 100000,\n",
    "    \"training.n_steps\": 100,\n",
    "    \"training.n_processes\": n_instances,\n",
    "    \"training.verbose\": 5,\n",
    "    \"outputs.path\": \"miniwob_click_button.p\"\n",
    "}\n",
    "\n",
    "\n",
    "train_ppo(envs, agent, train_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (rllr)",
   "language": "python",
   "name": "rllr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
