{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "device = \"cuda:1\"\n",
    "\n",
    "# Setup: and Selenium chrome driver to PATH and set MINIWOB_BASE_URL env variable to the directory with HTML task files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: file:///mnt/akostin/home/akostin/prjs/miniwob-plusplus/html/\n"
     ]
    }
   ],
   "source": [
    "from miniwob.environment import MiniWoBEnvironment\n",
    "from miniwob.action import  MiniWoBCoordClick\n",
    "from miniwob.screenshot import pil_to_numpy_array\n",
    "\n",
    "task_name = 'click-button'\n",
    "base_url = os.environ.get('MINIWOB_BASE_URL')\n",
    "print('BASE URL:', base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x210 at 0x7FF0ADD9D4C0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MiniWoBEnvironment(task_name, seeds=[1], num_instances=1, base_url=base_url, headless=True)\n",
    "state = env.reset(record_screenshots=True, seeds=[1123])\n",
    "state[0].screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff0f9e29e50>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b647ed59766295aca157c5463af7ae17\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff1205e7e20>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b647ed59766295aca157c5463af7ae17\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff0add7e160>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/b647ed59766295aca157c5463af7ae17\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "X_MAX, Y_MAX = 160, 210\n",
    "DOM_TEXT_MAX_TOKENS = 8\n",
    "GOAL_MAX_TOKENS = 16\n",
    "DOM_MAX_EDGES = 20\n",
    "DOM_MAX_VERTICES = 20\n",
    "\n",
    "\n",
    "class DOMVertex():\n",
    "    def __init__(self, dom_element, i, text_tokenizer, tokenization_kwargs):\n",
    "        self.id = i\n",
    "        self.tag = dom_element.tag\n",
    "        self.cx, self.cy, self.width, self.height = (dom_element.left + dom_element.width/2)/X_MAX, \\\n",
    "                                                    (dom_element.top + dom_element.height/2)/Y_MAX, \\\n",
    "                                                    dom_element.width/X_MAX, dom_element.height/Y_MAX\n",
    "        self.focused = dom_element.focused\n",
    "        self.tampered = dom_element.tampered\n",
    "        text = dom_element.text if dom_element.text else \"\"\n",
    "        self.text_tokens = text_tokenizer(text, **tokenization_kwargs)['input_ids']\n",
    "    \n",
    "    def get_feat_vector(self):\n",
    "        simple_feats = torch.tensor([self.cx, self.cy, self.width, self.height, self.focused, self.tampered],\\\n",
    "                                    dtype=torch.float32)\n",
    "        return simple_feats, self.text_tokens\n",
    "\n",
    "\n",
    "class DOMTree():\n",
    "    def __init__(self, text_tokenizer=None, tokenization_kwargs=dict()):\n",
    "        self.i=0\n",
    "        if text_tokenizer:\n",
    "            self.text_tokenizer = text_tokenizer\n",
    "            self.tokenization_kwargs = tokenization_kwargs\n",
    "        else:\n",
    "            self.text_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "            self.tokenization_kwargs ={\"padding\": 'max_length',\n",
    "                                       \"max_length\": DOM_TEXT_MAX_TOKENS,\n",
    "                                       \"truncation\": True,\n",
    "                                       \"return_tensors\": \"pt\",}\n",
    "        self.vertices = list()\n",
    "        self.fr0m = list()\n",
    "        self.to = list()\n",
    "    \n",
    "    def build_tree(self, root_element):\n",
    "        candidates = [(root_element, -1)]\n",
    "        while len(candidates):\n",
    "            element, parent_id = candidates.pop()\n",
    "            self.vertices.append(DOMVertex(element, self.i, self.text_tokenizer, self.tokenization_kwargs))\n",
    "            if parent_id>=0:\n",
    "                self.fr0m.append(parent_id)\n",
    "                self.to.append(self.i)\n",
    "            candidates += [(child, self.i) for child in element.children]\n",
    "            self.i += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        self.vertices = list()\n",
    "        self.fr0m = list()\n",
    "        self.to = list()\n",
    "        self.i = 0\n",
    "    \n",
    "    def get_data(self):\n",
    "        simple, text = list(), list()\n",
    "        for vertex in self.vertices:\n",
    "            s, t = vertex.get_feat_vector()\n",
    "            simple.append(s); text.append(t)\n",
    "        \n",
    "        delta_e = DOM_MAX_EDGES - len(self.fr0m)\n",
    "        self.fr0m += [-1 for i in range(delta_e)]\n",
    "        self.to += [-1 for i in range(delta_e)]\n",
    "        \n",
    "        delta_v = DOM_MAX_VERTICES - len(simple)\n",
    "        simple += [-torch.ones((6,), dtype=torch.float32) for i in range(delta_v)]\n",
    "        text += [torch.zeros((1, DOM_TEXT_MAX_TOKENS), dtype=torch.int64) for i in range(delta_v)]\n",
    "        \n",
    "        return {\n",
    "            \"dom_from\": torch.tensor(self.fr0m, dtype=torch.int64).unsqueeze(0),\n",
    "            \"dom_to\": torch.tensor(self.to, dtype=torch.int64).unsqueeze(0),\n",
    "            \"dom_simple_feats\": torch.stack(simple, dim=0).unsqueeze(0),\n",
    "            \"dom_text_tokens\": torch.cat(text, dim=0).unsqueeze(0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym miniwob wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "\n",
    "from miniwob.action import MiniWoBElementClick, MiniWoBCoordClick\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MiniWobClickButtonWrapper(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        bert_model = 'bert-base-cased'\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        self.tree = DOMTree()\n",
    "        \n",
    "        self.observation_space = gym.spaces.Dict({\"goal_state\": gym.spaces.Box(0, \n",
    "                                                                              self.tokenizer.vocab_size,\n",
    "                                                                               (GOAL_MAX_TOKENS, ),\n",
    "                                                                              dtype=np.int64),\n",
    "                                                  \"img_state\": gym.spaces.Box(0,\n",
    "                                                                        255,\n",
    "                                                                        (150, 150, 3),\n",
    "                                                                        dtype=np.uint8),\n",
    "                                                  \"dom_simple_feats\": gym.spaces.Box(-1,\n",
    "                                                                                     1,\n",
    "                                                                                     (DOM_MAX_VERTICES, 6),\n",
    "                                                                                     dtype=np.float32),\n",
    "                                                  \"dom_text_tokens\": gym.spaces.Box(0,\n",
    "                                                                                    self.tokenizer.vocab_size,\n",
    "                                                                                    (DOM_MAX_VERTICES, DOM_TEXT_MAX_TOKENS),\n",
    "                                                                                    dtype=np.int64),\n",
    "                                                  \"dom_from\": gym.spaces.Box(-1,\n",
    "                                                                             DOM_MAX_VERTICES,\n",
    "                                                                             (DOM_MAX_EDGES, ),\n",
    "                                                                             dtype=np.int64),\n",
    "                                                  \"dom_to\": gym.spaces.Box(-1,\n",
    "                                                                           DOM_MAX_VERTICES,\n",
    "                                                                           (DOM_MAX_EDGES, ),\n",
    "                                                                           dtype=np.int64)})\n",
    "        \n",
    "        self.dom_keys = [key for key in self.observation_space if key.startswith(\"dom\")]\n",
    "        self.h, self.w = 210, 160\n",
    "        self.grid_step = 10\n",
    "        n_actions = int(self.h/self.grid_step+1) * int(self.w/self.grid_step+1)\n",
    "        self.action_space = gym.spaces.Discrete(n_actions)\n",
    "    \n",
    "    def _ob_to_dom(self, ob):\n",
    "        max_length = DOM_TEXT_MAX_TOKENS\n",
    "        if ob is None:\n",
    "            return {\n",
    "                \"dom_simple_feats\": -torch.ones((1, DOM_MAX_VERTICES, 6), dtype=torch.float32),\n",
    "                \"dom_text_tokens\": torch.zeros((1, DOM_MAX_VERTICES, DOM_TEXT_MAX_TOKENS), dtype=torch.int64),\n",
    "                \"dom_from\": -torch.ones((1, DOM_MAX_EDGES), dtype=torch.int64),\n",
    "                \"dom_to\": -torch.ones((1, DOM_MAX_EDGES), dtype=torch.int64)\n",
    "            }\n",
    "        else:\n",
    "            self.tree.reset()\n",
    "            self.tree.build_tree(ob.dom)\n",
    "            return self.tree.get_data()\n",
    "    \n",
    "    def _ob_to_token(self, ob):\n",
    "        max_length = GOAL_MAX_TOKENS\n",
    "        if ob is None:\n",
    "            return torch.zeros(1, max_length)\n",
    "        else: \n",
    "            return self.tokenizer(ob.tokens,  \n",
    "                                  padding='max_length', \n",
    "                                  max_length = max_length, truncation=True,          \n",
    "                                  return_tensors=\"pt\",\n",
    "                                  is_split_into_words=True)['input_ids']\n",
    "            \n",
    "    def _ob_to_image(self, ob):\n",
    "        if ob is None:\n",
    "            return torch.zeros(1, 150, 150, 3)\n",
    "        else:\n",
    "            return torch.tensor(pil_to_numpy_array(ob.screenshot.resize([150, 150]))).unsqueeze(0)\n",
    "        \n",
    "    \n",
    "    def _to_miniwob_actions(self, actions):\n",
    "        \n",
    "        n_x = int(self.w/self.grid_step + 1)        \n",
    "        actions = actions.squeeze()\n",
    "        miniwob_actions = []\n",
    "        \n",
    "        for i in range(self.num_instances):\n",
    "            if self.instances[i].get_metadata()['done']:\n",
    "                miniwob_actions.append(None)\n",
    "            else:\n",
    "                k = actions[i].item()\n",
    "                x, y = k%n_x * self.grid_step, int(k/n_x) * self.grid_step\n",
    "                miniwob_actions.append(MiniWoBCoordClick(x, y))\n",
    "        return miniwob_actions\n",
    "\n",
    "    def observation(self, obs):\n",
    "        goals = torch.cat([self._ob_to_token(ob) for ob in obs], dim=0)\n",
    "        imgs = torch.cat([self._ob_to_image(ob) for ob in obs], dim=0)\n",
    "        doms = [self._ob_to_dom(ob) for ob in obs]\n",
    "        doms_states = {key: torch.cat([dom[key] for dom in doms], dim=0) for key in self.dom_keys}\n",
    "        return {'img_state': imgs, 'goal_state': goals, **doms_states}\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.observation(self.env.reset(record_screenshots=True))\n",
    "    \n",
    "    def step(self, actions):\n",
    "        miniwob_actions = self._to_miniwob_actions(actions)\n",
    "        obs, rewards, dones, infos = self.env.step(miniwob_actions)        \n",
    "        obs = self.observation(obs)\n",
    "        \n",
    "        for instance in self.env.instances:\n",
    "            if instance.get_metadata()['done']:\n",
    "                instance.begin_task()\n",
    "        \n",
    "        return obs, torch.tensor([rewards]).T, torch.tensor([dones]).T, infos['n']\n",
    "\n",
    "\n",
    "class EpisodeInfoWrapper(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env, n):\n",
    "        super(EpisodeInfoWrapper, self).__init__(env)\n",
    "        self.episode_reward = np.zeros(n)\n",
    "        self.episode_steps = np.zeros(n)\n",
    "        self.n = n\n",
    "\n",
    "    def reset(self):\n",
    "        self.episode_reward = np.zeros(self.n)\n",
    "        self.episode_steps = np.zeros(self.n)\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, actions):\n",
    "        states, rewards, dones, infos = self.env.step(actions)\n",
    "        \n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                self.episode_reward[i] = rewards[i]\n",
    "                self.episode_steps[i] += 1\n",
    "                infos[i]['episode'] = {'r': self.episode_reward[i], 'steps': self.episode_steps[i]}\n",
    "                \n",
    "        return states, rewards, dones, infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import relu\n",
    "import torch\n",
    "\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        bert_model = 'bert-base-cased'\n",
    "        \n",
    "        self.bert_encoder = BertModel.from_pretrained(bert_model)\n",
    "        self.embed_dim = 768\n",
    "        self.output_size = 64\n",
    "        self.out_layer = nn.Linear(self.embed_dim, self.output_size)\n",
    "        tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        self.pad_token = tokenizer.pad_token_id\n",
    "   \n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Encode batch of tokens\n",
    "        \n",
    "        \"\"\"\n",
    "        text_tokens_embed = self.bert_encoder(input_ids.long())[0]\n",
    "        with torch.no_grad():\n",
    "            embeds = relu(self.out_layer(text_tokens_embed))\n",
    "        \n",
    "        pad_mask = torch.where(input_ids.long() == self.pad_token, True, False)\n",
    "        return embeds, pad_mask\n",
    "\n",
    "\n",
    "class DOMBert(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        bert_model = 'bert-base-cased'\n",
    "        \n",
    "        self.bert_encoder = BertModel.from_pretrained(bert_model)\n",
    "        self.embed_dim = 768\n",
    "        self.output_size = 64 - 6\n",
    "        self.out_layer = nn.Linear(self.embed_dim, self.output_size)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Encode batch of tokens\n",
    "        \n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            text_tokens_embed = self.bert_encoder(input_ids.long())[1]\n",
    "        out = relu(self.out_layer(text_tokens_embed))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "import torch\n",
    "from torch.nn import ModuleList, Parameter, TransformerEncoderLayer, TransformerEncoder\n",
    "from torch.nn.functional import relu, softmax\n",
    "\n",
    "\n",
    "UNDIRECTED = True\n",
    "SELF_LOOP = True\n",
    "bert_model = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        in_feats, h_dim, n_layers = 64, 64, 1\n",
    "        in_layer = GraphConv(in_feats, h_dim)\n",
    "        self.layers = ModuleList([in_layer, *[GraphConv(h_dim, h_dim) for i in range(n_layers-1)]])\n",
    "    \n",
    "    def forward(self, graph, features):\n",
    "        out = features\n",
    "        for layer in self.layers:\n",
    "            out = layer(graph, out)\n",
    "            out = relu(out)\n",
    "        return graph\n",
    "\n",
    "\n",
    "class DOMNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOMNET, self).__init__()\n",
    "        self.gcn = GCN()\n",
    "        self.bert = DOMBert()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        graphs = list()\n",
    "        for fr0m, to, simple_feats, text_tokens in zip(input[\"dom_from\"], input[\"dom_to\"],\\\n",
    "                                                       input[\"dom_simple_feats\"], input[\"dom_text_tokens\"]):\n",
    "            \n",
    "            edge_mask = fr0m!=-1\n",
    "            vertex_mask = torch.all(simple_feats!=-torch.ones_like(simple_feats[0]), dim=1)\n",
    "            fr0m = fr0m[edge_mask]\n",
    "            to = to[edge_mask]\n",
    "            simple_feats = simple_feats[vertex_mask]\n",
    "            text_tokens = text_tokens[vertex_mask]\n",
    "            \n",
    "            text_embed = self.bert(text_tokens)\n",
    "            vertices_embeds = torch.cat([text_embed, simple_feats], dim=-1)\n",
    "            \n",
    "            graph = dgl.graph((fr0m.long(), to.long()))\n",
    "            graph.ndata['vertex_embed'] = vertices_embeds\n",
    "            if UNDIRECTED:\n",
    "                graph = dgl.add_reverse_edges(graph)\n",
    "            if SELF_LOOP:\n",
    "                graph = dgl.add_self_loop(graph)\n",
    "            graphs.append(graph)\n",
    "        \n",
    "        batch_graph = dgl.batch(graphs)\n",
    "        batch_graph = self.gcn(batch_graph, batch_graph.ndata['vertex_embed'])\n",
    "        \n",
    "        graphs = [graph.ndata[\"vertex_embed\"] for graph in dgl.unbatch(batch_graph)]\n",
    "        embeds, mask = self.collate_fn(graphs)\n",
    "        return embeds, mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(tensor_list):\n",
    "        vec_dim = tensor_list[0].shape[1]\n",
    "        max_n_vec = max([t.shape[0] for t in tensor_list])\n",
    "        bs = len(tensor_list)\n",
    "\n",
    "        pad_mask = torch.zeros((bs, max_n_vec), dtype=torch.bool).to(device)\n",
    "        pad_vector = torch.zeros((1, vec_dim)).to(device)\n",
    "\n",
    "        for i in range(bs):\n",
    "            delta = max_n_vec - tensor_list[i].shape[0]\n",
    "            pad = torch.repeat_interleave(pad_vector, delta, dim=0)\n",
    "            tensor_list[i] = torch.cat([tensor_list[i], pad], dim=0)\n",
    "            pad_mask[i, -delta:] = True\n",
    "\n",
    "        return torch.stack(tensor_list, dim=1), pad_mask\n",
    "\n",
    "\n",
    "class DOMGoalTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOMGoalTransformer, self).__init__()\n",
    "        self.inp_dim = 64\n",
    "        self.output_size = self.inp_dim\n",
    "        \n",
    "        self.embed_token = nn.Parameter(torch.empty(1, 1, self.inp_dim))\n",
    "        nn.init.uniform_(self.embed_token, -0.1, 0.1)\n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(64, 4, dim_feedforward=64, norm_first=True)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, 1)\n",
    "    \n",
    "    def forward(self, inp, mask):\n",
    "        mask = torch.cat([torch.zeros_like(mask[:, :1], dtype=torch.bool), mask], dim=1)\n",
    "        inp = torch.cat([self.embed_token.repeat_interleave(inp.shape[1], dim=1), inp], dim=0)\n",
    "        out = self.encoder(inp, src_key_padding_mask=mask)\n",
    "        return out[0]\n",
    "\n",
    "\"\"\"\n",
    "class DOMGoalAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOMGoalAttention, self).__init__()\n",
    "    def forward(self, input):\n",
    "        vertices_embed, goal_embed = input[1:DOM_MAX_VERTICES], input[-GOAL_MAX_TOKENS:]\n",
    "        # vertices_embed.shape = (DOM_MAX_VERTICES, batch, dim)\n",
    "        # goal_embed.shape = (GOAL_MAX_TOKENS, batch, dim)\n",
    "        vertices_embed = vertices_embed.permute([1,0,2])\n",
    "        goal_embed = goal_embed.permute([1, 2, 0])\n",
    "        attn = softmax(torch.matmul(vertices_embed, goal_embed))\n",
    "        return attn\n",
    "\"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img, dom=DOMNET(), goal=BertEncoder(), tf=DOMGoalTransformer()):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.img_encoder = img\n",
    "        self.dom_net = dom\n",
    "        self.goal_bert = goal\n",
    "        self.tf = tf\n",
    "        self.output_size = self.img_encoder.output_size + 64\n",
    "    \n",
    "    def forward(self, input):\n",
    "        dom_embeds, dom_mask = self.dom_net(input)\n",
    "        goal_embeds, goal_mask = self.goal_bert(input[\"goal_state\"])\n",
    "        dom_goal_embeds = torch.cat([dom_embeds, goal_embeds.permute([1, 0, 2])], dim=0)\n",
    "        dom_goal_mask = torch.cat([dom_mask, goal_mask], dim=1)\n",
    "        tf_out = self.tf(dom_goal_embeds, dom_goal_mask)\n",
    "        \n",
    "        img_out = self.img_encoder(input[\"img_state\"])\n",
    "        \n",
    "        out = torch.cat([tf_out, img_out], dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rllr.env.vec_wrappers import make_vec_envs\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "def get_envs(n, **kwargs):\n",
    "    env = MiniWoBEnvironment(task_name, seeds=range(n), num_instances=n, base_url=base_url, **kwargs)\n",
    "    env = MiniWobClickButtonWrapper(env)\n",
    "    return EpisodeInfoWrapper(env, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n_instances = 8\n",
    "envs = get_envs(n_instances, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from rllr.models.encoders import GoalStateEncoder, SimpleCNN\n",
    "\n",
    "conf = {\n",
    "    \"n_channels\": [32, 64, 64],\n",
    "    \"kernel_sizes\": [4, 4, 3],\n",
    "    \"strides\": [4, 2, 1],\n",
    "    \"hidden_layers_sizes\": [64]\n",
    "}\n",
    "\n",
    "img = SimpleCNN(grid_size=150, conf=conf)\n",
    "encoder = Encoder(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rllr.algo.ppo.PPO at 0x7ff0a43f43d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rllr.algo import PPO\n",
    "from rllr.models.ppo import ActorCriticNetwork\n",
    "\n",
    "hidden_size = 32\n",
    "policy = ActorCriticNetwork(envs.action_space, encoder, encoder, hidden_size, hidden_size)\n",
    "\n",
    "agent_conf = {\n",
    "        \"clip_param\": 0.2,\n",
    "        \"ppo_epoch\": 4,\n",
    "        \"num_mini_batch\": 4,\n",
    "        \"value_loss_coef\": 0.5,\n",
    "        \"entropy_coef\": 0.01,\n",
    "        \"lr\": 0.001,\n",
    "        \"eps\": 1e-5,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "}\n",
    "\n",
    "\n",
    "agent = PPO(policy, **agent_conf)\n",
    "agent.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from rllr.utils.training import train_ppo\n",
    "\n",
    "train_conf = {\n",
    "    \"agent.lr\": 0.001,\n",
    "    \"agent.device\": device,\n",
    "    \"agent.gamma\": 0.99,\n",
    "    \"agent.gae_lambda\": 0.95,\n",
    "    \"training.n_env_steps\": 500000,\n",
    "    \"training.n_steps\": 50,\n",
    "    \"training.n_processes\": n_instances,\n",
    "    \"training.verbose\": 1,\n",
    "    \"outputs.path\": \"miniwob_cnn_gcn.p\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    }
   ],
   "source": [
    "print(\"starting training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                                                                                                                                                                           | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([0, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([0, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([0, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([0, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([9, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([9, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "dom:  torch.Size([12, 200, 64])\n",
      "goal:  torch.Size([16, 200, 64])\n",
      "Updates 0, num timesteps 800, FPS 0 \n",
      "Last 10 training episodes: mean/median reward -0.52/-1.00, min/max reward -1.00/0.65\n",
      "dist_entropy 5.68, value_loss 0.35, action_loss 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|▎                                                                                                                                                                                             | 1/625 [13:38<141:56:27, 818.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([0, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([0, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([10, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([13, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([13, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([13, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([13, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([13, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([13, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([12, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n",
      "dom:  torch.Size([11, 8, 64])\n",
      "goal:  torch.Size([16, 8, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                                             | 1/625 [14:45<153:30:57, 885.67s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19475/802183639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ppo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/akostin/home/akostin/p38/lib/python3.8/site-packages/rllr/utils/training.py\u001b[0m in \u001b[0;36mtrain_ppo\u001b[0;34m(env, agent, conf)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Sample actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'agent.device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/akostin/home/akostin/p38/lib/python3.8/site-packages/rllr/algo/ppo.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state, deterministic)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/akostin/home/akostin/p38/lib/python3.8/site-packages/rllr/models/ppo.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, deterministic)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/akostin/home/akostin/p38/lib/python3.8/site-packages/rllr/models/ppo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/akostin/home/akostin/p38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19475/3457169339.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mdom_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdom_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdom_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mgoal_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoal_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"goal_state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dom: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdom_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/akostin/home/akostin/p38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19475/3457169339.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                                        input[\"dom_simple_feats\"], input[\"dom_text_tokens\"]):\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0medge_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr0m\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mvertex_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_feats\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mfr0m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr0m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_ppo(envs, agent, train_conf)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "train_ppo(envs, agent, train_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
